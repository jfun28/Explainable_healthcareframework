{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 외부데이터세트로 일반화 성능테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 전혀 사용하지 않은 모집단을 제주 B초등학교에서 추가로 수집하여  \n",
    "서울 A초등학교로 학습한 모델이 이 외부데이터 세트인 B초등학교에서도 성능이 잘 나오는지 테스트하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score ## F1 Score 구하기\n",
    "from sklearn.metrics import precision_recall_fscore_support as sk\n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "path=os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제주 B초등학교 테스트 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeju_data=pd.read_csv(path+\"\\\\data\\\\6.제주초_testdataset.csv\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  데이터 세트 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=jeju_data.iloc[:,[1,2,3,4,5,6,8]]\n",
    "train=data.iloc[:,:-1]\n",
    "train_targets=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_targets = encoder.fit_transform(train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=train.to_numpy()\n",
    "y_test=train_targets\n",
    "y_test=y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = X_test\n",
    "\n",
    "test_targets_np=y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성 method 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generation_list = ['smote','adasyn','copulagan','ctgan','nbsynthetic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제안한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final_emb: torch.Size([3311, 6])\n",
      "Final embeddings shape: (3311, 6)\n",
      "Unique values in prediction: [0 1 2]\n",
      "Shape of final_emb: torch.Size([3311, 6])\n",
      "Final embeddings shape: (3311, 6)\n",
      "Unique values in prediction: [0 1 2]\n",
      "Shape of final_emb: torch.Size([3311, 6])\n",
      "Final embeddings shape: (3311, 6)\n",
      "Unique values in prediction: [0 1 2]\n",
      "Shape of final_emb: torch.Size([3311, 6])\n",
      "Final embeddings shape: (3311, 6)\n",
      "Unique values in prediction: [0 1 2]\n",
      "Shape of final_emb: torch.Size([3311, 6])\n",
      "Final embeddings shape: (3311, 6)\n",
      "Unique values in prediction: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "def extract_tabnet_embeddings(\n",
    "    tabnet_model,\n",
    "    X_tensor,\n",
    "    device=None,\n",
    "    batch_size=5000\n",
    "    ):\n",
    "        if device is None:\n",
    "            device = next(tabnet_model.network.parameters()).device\n",
    "        \n",
    "        tabnet_model.network.eval()\n",
    "        tabnet_model.network.to(device)\n",
    "        X_tensor = X_tensor.to(device)\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        all_embeddings = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (xb,) in loader:\n",
    "                embeddings, _ = tabnet_model.network.forward_masks(xb)\n",
    "                        \n",
    "                if isinstance(embeddings, dict):\n",
    "                    if 'embeddings' in embeddings:\n",
    "                        final_emb = embeddings['embeddings'][-1]\n",
    "                    else:\n",
    "                        final_emb = list(embeddings.values())[-1]\n",
    "                else:\n",
    "                    # embeddings가 리스트인 경우, 마지막 decision step의 embedding 사용\n",
    "                    if isinstance(embeddings, list):\n",
    "                        final_emb = embeddings[-1]\n",
    "                    else:\n",
    "                        final_emb = embeddings\n",
    "                \n",
    "                # final_emb의 shape 확인\n",
    "                print(\"Shape of final_emb:\", final_emb.shape)\n",
    "                \n",
    "                all_embeddings.append(final_emb.cpu().numpy())\n",
    "        \n",
    "        final_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "        # 최종 shape 출력\n",
    "        print(\"Final embeddings shape:\", final_embeddings.shape)\n",
    "        return final_embeddings\n",
    "\n",
    "for generation in Generation_list:\n",
    "    # TabNet 모델 로드\n",
    "    with open(path+f'\\\\3.Training_XAI\\\\model_hist\\\\{generation}_proposed_tabnetEmbedd.pickle', 'rb') as f:\n",
    "        tabnet_clf = pickle.load(f)\n",
    "        \n",
    "        \n",
    "    with open(path+f'\\\\3.Training_XAI\\\\scaler_hist\\\\{generation}_proposed_standard_scaler.pickle', 'rb') as f:\n",
    "        standard_scaler = pickle.load(f)\n",
    "    \n",
    "    # XGBoost 모델 로드 \n",
    "    with open(path+f'\\\\3.Training_XAI\\\\model_hist\\\\{generation}_proposed.pickle', 'rb') as f:\n",
    "        proposed_model = pickle.load(f)\n",
    "\n",
    "    # 테스트 데이터를 텐서로 변환\n",
    "    X_test_torch = torch.from_numpy(test_np.astype(np.float32))\n",
    "    \n",
    "    # TabNet 임베딩 추출\n",
    "    test_embeddings = extract_tabnet_embeddings(\n",
    "        tabnet_clf,\n",
    "        X_test_torch,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    test_embeddings_scaled = standard_scaler.transform(test_embeddings)\n",
    "    \n",
    "    # XGBoost로 예측\n",
    "    predict = proposed_model.predict(test_embeddings_scaled).astype(int)\n",
    "    \n",
    "    # predict=predict+1\n",
    "    unique_values = np.array(list(set(predict)))\n",
    "    print(f\"Unique values in prediction: {unique_values}\")\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    accuracy = accuracy_score(test_targets_np, predict)\n",
    "    f1 = f1_score(test_targets_np, predict, average='weighted')\n",
    "    precision, recall = sk(test_targets_np, predict, beta=1, average='weighted')[:2]\n",
    "    \n",
    "    results.append({\n",
    "        'Model': f\"{generation}-proposed_external\",\n",
    "        'Accuracy': round(accuracy, 5),\n",
    "        'F1score': round(f1, 5), \n",
    "        'Precision': round(precision, 5),\n",
    "        'Recall': round(recall, 5)\n",
    "    })\n",
    "\n",
    "df_proposed_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in test_targets_np: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "unique_values = np.unique(test_targets_np)\n",
    "print(f\"Unique values in test_targets_np: {unique_values}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smote-proposed_external</td>\n",
       "      <td>0.81637</td>\n",
       "      <td>0.80780</td>\n",
       "      <td>0.79984</td>\n",
       "      <td>0.81637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adasyn-proposed_external</td>\n",
       "      <td>0.82332</td>\n",
       "      <td>0.80389</td>\n",
       "      <td>0.78653</td>\n",
       "      <td>0.82332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>copulagan-proposed_external</td>\n",
       "      <td>0.43612</td>\n",
       "      <td>0.53980</td>\n",
       "      <td>0.78457</td>\n",
       "      <td>0.43612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ctgan-proposed_external</td>\n",
       "      <td>0.58653</td>\n",
       "      <td>0.66540</td>\n",
       "      <td>0.78220</td>\n",
       "      <td>0.58653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nbsynthetic-proposed_external</td>\n",
       "      <td>0.84144</td>\n",
       "      <td>0.81121</td>\n",
       "      <td>0.78408</td>\n",
       "      <td>0.84144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy  F1score  Precision   Recall\n",
       "0        smote-proposed_external   0.81637  0.80780    0.79984  0.81637\n",
       "1       adasyn-proposed_external   0.82332  0.80389    0.78653  0.82332\n",
       "2    copulagan-proposed_external   0.43612  0.53980    0.78457  0.43612\n",
       "3        ctgan-proposed_external   0.58653  0.66540    0.78220  0.58653\n",
       "4  nbsynthetic-proposed_external   0.84144  0.81121    0.78408  0.84144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proposed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임을 CSV 파일로 저장 (선택사항)\n",
    "df_proposed_results.to_csv('proposed_model_metrics_externaltest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\jupyter\\\\Explainable Healthcare framework\\\\Explainable_healthcareframework\\\\3.Training_XAI\\\\model_hist\\\\smote_DT_model.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m Generation_list:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m3.Training_XAI\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mmodel_hist\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgeneration\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_DT_model.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m         DT_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m     predict\u001b[38;5;241m=\u001b[39mDT_model\u001b[38;5;241m.\u001b[39mpredict(test_np)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jaemin\\anaconda3\\envs\\jm_main\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\jupyter\\\\Explainable Healthcare framework\\\\Explainable_healthcareframework\\\\3.Training_XAI\\\\model_hist\\\\smote_DT_model.pickle'"
     ]
    }
   ],
   "source": [
    "# 빈 리스트 생성하여 결과 저장\n",
    "results = []\n",
    "\n",
    "for generation in Generation_list:\n",
    "    with open(path+f'\\\\3.Training_XAI\\\\model_hist\\\\{generation}_DT_model.pickle', 'rb') as f:\n",
    "        DT_model = pickle.load(f)\n",
    "    predict=DT_model.predict(test_np).astype(int)\n",
    "    # 각 메트릭 계산\n",
    "    accuracy = DT_model.score(test_np, test_targets_np)\n",
    "    f1 = f1_score(test_targets_np, predict, average='weighted')\n",
    "    precision, recall = sk(test_targets_np, predict, beta=1, average='weighted')[:2]\n",
    "    \n",
    "    # 결과를 딕셔너리로 저장\n",
    "    result_dict = {\n",
    "        'Model': f\"{generation}-Decision Tree\",\n",
    "        'Accuracy': round(accuracy, 5),\n",
    "        'F1score': round(f1, 5),\n",
    "        'Precision': round(precision, 5),\n",
    "        'Recall': round(recall, 5)\n",
    "    }\n",
    "    \n",
    "    # 리스트에 딕셔너리 추가\n",
    "    results.append(result_dict)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_DT_results = pd.DataFrame(results)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장 (선택사항)\n",
    "# df_results.to_csv('model_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DT_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_model = GaussianNB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 리스트 생성하여 결과 저장\n",
    "results = []\n",
    "\n",
    "for generation in Generation_list:\n",
    "    with open(f'C:\\\\jupyter\\\\Elementary-student-Weight\\\\GAN_XAI\\\\Experiment3(생성별_모델별)\\\\model_history\\\\{generation}_NB_model.pickle', 'rb') as f:\n",
    "        NB_model = pickle.load(f)\n",
    "    predict=NB_model.predict(test_np).astype(int)\n",
    "    # 각 메트릭 계산\n",
    "    accuracy = NB_model.score(test_np, test_targets_np)\n",
    "    f1 = f1_score(test_targets_np, predict, average='weighted')\n",
    "    precision, recall = sk(test_targets_np, predict, beta=1, average='weighted')[:2]\n",
    "    \n",
    "    # 결과를 딕셔너리로 저장\n",
    "    result_dict = {\n",
    "        'Model': f\"{generation}-Naive Bayes\",\n",
    "        'Accuracy': round(accuracy, 5),\n",
    "        'F1score': round(f1, 5),\n",
    "        'Precision': round(precision, 5),\n",
    "        'Recall': round(recall, 5)\n",
    "    }\n",
    "    \n",
    "    # 리스트에 딕셔너리 추가\n",
    "    results.append(result_dict)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_Naive_results = pd.DataFrame(results)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장 (선택사항)\n",
    "# df_results.to_csv('model_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "LDA_model= LinearDiscriminantAnalysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 리스트 생성하여 결과 저장\n",
    "results = []\n",
    "\n",
    "for generation in Generation_list:\n",
    "    with open(f'C:\\\\jupyter\\\\Elementary-student-Weight\\\\GAN_XAI\\\\Experiment3(생성별_모델별)\\\\model_history\\\\{generation}_LDA_model.pickle', 'rb') as f:\n",
    "        LDA_model = pickle.load(f)\n",
    "    predict=LDA_model.predict(test_np).astype(int)\n",
    "    # 각 메트릭 계산\n",
    "    accuracy = LDA_model.score(test_np, test_targets_np)\n",
    "    f1 = f1_score(test_targets_np, predict, average='weighted')\n",
    "    precision, recall = sk(test_targets_np, predict, beta=1, average='weighted')[:2]\n",
    "    \n",
    "    # 결과를 딕셔너리로 저장\n",
    "    result_dict = {\n",
    "        'Model': f\"{generation}-LDA\",\n",
    "        'Accuracy': round(accuracy, 5),\n",
    "        'F1score': round(f1, 5),\n",
    "        'Precision': round(precision, 5),\n",
    "        'Recall': round(recall, 5)\n",
    "    }\n",
    "    \n",
    "    # 리스트에 딕셔너리 추가\n",
    "    results.append(result_dict)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_LDA_results = pd.DataFrame(results)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장 (선택사항)\n",
    "# df_results.to_csv('model_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LDA_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 로드 및 전처리 (예시)\n",
    "# X 데이터는 6개의 특징 변수, y 데이터는 라벨 (1.0, 2.0, 3.0)\n",
    "# X, y 데이터는 적절히 로드되어 있어야 합니다.\n",
    "# 모델 정의\n",
    "\n",
    "Logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 리스트 생성하여 결과 저장\n",
    "results = []\n",
    "scaler=StandardScaler()\n",
    "for generation in Generation_list:\n",
    "    with open(f'C:\\\\jupyter\\\\Elementary-student-Weight\\\\GAN_XAI\\\\Experiment3(생성별_모델별)\\\\model_history\\\\{generation}_Logistic_model.pickle', 'rb') as f:\n",
    "        Logistic_model = pickle.load(f)\n",
    "    \n",
    "    with open(f'C:\\\\jupyter\\\\Elementary-student-Weight\\\\GAN_XAI\\\\Experiment3(생성별_모델별)\\\\model_history\\\\{generation}_Logistic_scaler.pickle', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    X_test=scaler.transform(test_np)\n",
    "    predict=Logistic_model.predict(X_test).astype(int)\n",
    "    # 각 메트릭 계산\n",
    "    accuracy = Logistic_model.score(X_test, test_targets_np)\n",
    "    f1 = f1_score(test_targets_np, predict, average='weighted')\n",
    "    precision, recall = sk(test_targets_np, predict, beta=1, average='weighted')[:2]\n",
    "    \n",
    "    # 결과를 딕셔너리로 저장\n",
    "    result_dict = {\n",
    "        'Model': f\"{generation}-LogisticRegression\",\n",
    "        'Accuracy': round(accuracy, 5),\n",
    "        'F1score': round(f1, 5),\n",
    "        'Precision': round(precision, 5),\n",
    "        'Recall': round(recall, 5)\n",
    "    }\n",
    "    \n",
    "    # 리스트에 딕셔너리 추가\n",
    "    results.append(result_dict)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_LogisticRegression_results = pd.DataFrame(results)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장 (선택사항)\n",
    "# df_results.to_csv('model_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LogisticRegression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from pygam import LogisticGAM, s, f\n",
    "\n",
    "def train_multiclass_gam(X_test, y_test):\n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    y_test_encoded = le.fit_transform(y_test)\n",
    "    n_classes = len(np.unique(y_test_encoded))\n",
    "\n",
    "    return y_test_encoded, le\n",
    "\n",
    "def predict_multiclass(gam_models, X):\n",
    "    # 각 클래스에 대한 예측 확률 계산\n",
    "    probs = np.column_stack([\n",
    "        gam.predict_proba(X) for gam in gam_models\n",
    "    ])\n",
    "    \n",
    "    # 가장 높은 확률을 가진 클래스 선택\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "def print_model_summary(gam_models, class_names):\n",
    "    print(\"\\n모델 요약:\")\n",
    "    for i, gam in enumerate(gam_models):\n",
    "        print(f\"\\n클래스 {class_names[i]}:\")\n",
    "        print(\"특성별 계수 정보:\")\n",
    "        for j, coef in enumerate(gam.coef_):\n",
    "            print(f\"특성 {j + 1} - 계수: {coef:.4f}\")\n",
    "        print(\"\\n모델 summary:\")\n",
    "        gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 리스트 생성하여 결과 저장\n",
    "results = []\n",
    "\n",
    "for generation in Generation_list:\n",
    "    with open(f'C:\\\\jupyter\\\\Elementary-student-Weight\\\\GAN_XAI\\\\Experiment3(생성별_모델별)\\\\model_history\\\\{generation}_gams_model.pickle', 'rb') as f:\n",
    "        GAMs_model = pickle.load(f)\n",
    "    y_test_encoded, le = train_multiclass_gam(train, train_targets)\n",
    "    predict = predict_multiclass(GAMs_model, train)\n",
    "    accuracy = accuracy_score(y_test_encoded, predict)\n",
    " \n",
    "    # 각 메트릭 계산\n",
    "    f1 = f1_score(y_test_encoded, predict, average='weighted')\n",
    "    precision, recall = sk(y_test_encoded, predict, beta=1, average='weighted')[:2]\n",
    "    \n",
    "    # 결과를 딕셔너리로 저장\n",
    "    result_dict = {\n",
    "        'Model': f\"{generation}-GAMs\",\n",
    "        'Accuracy': round(accuracy, 5),\n",
    "        'F1score': round(f1, 5),\n",
    "        'Precision': round(precision, 5),\n",
    "        'Recall': round(recall, 5)\n",
    "    }\n",
    "    \n",
    "    # 리스트에 딕셔너리 추가\n",
    "    results.append(result_dict)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_GAMs_results = pd.DataFrame(results)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장 (선택사항)\n",
    "# df_results.to_csv('model_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GAMs_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 총합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LDA_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LogisticRegression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml=pd.concat([df_DT_results,df_Naive_results,df_LDA_results,df_GAMs_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml=df_ml.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.to_csv('C:\\jupyter\\Elementary-student-Weight\\GAN_XAI\\Experiment3(생성별_모델별)\\data\\(하귀일)머신 러닝 일반화 성능 정리.csv',encoding='cp949',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jm_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
